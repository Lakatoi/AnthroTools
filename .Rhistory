}
if(!(Norm %in% list(T,F))){
stop('Specified "Norm" not a logical.')
}
for( iii in unique(mydata[,Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else{
mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]<- (max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]) - mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]+1)/max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]<-mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]/sum(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience])
}
}
}
return(mydata)
}
Book1<-CalculateSalience(Book1,Order="ORDER_NC", Subj="ID_NC",Norm=T)
warnings()
CalculateSalience <-
function(mydata, Order="Order",Subj="Subj",CODE="CODE",Norm=FALSE,Salience="Salience"){
##This is a script which, given a dataset containing a list of subjects,
##and an ordering of responses will compute the "salience" of each response.
##Salience is effectively "What fraction of the way up the list are we?"
##If an individual gives five responses to a freelisting question,
##the first will have salience 1, the second 4/5, the third 3/5 and so on.
##  If the "Normalise" value is true, saliences will be normalised such that each individual has
## a total salience of 1. Otherwise, the set will be normalised so they have a maximum salience of 1.
if(!(class(mydata)=="data.frame" )){
stop('"mydata" is not a data frame. That will make things not work.')
}
mydata[,Salience]<- 0
badSubjects=list()
if(!(Order %in% colnames(mydata))){
stop('Specified "Order" column not valid.')
}
if(!(Subj %in% colnames(mydata))){
stop('Specified "Subj" column not valid.')
}
if(!(CODE %in% colnames(mydata))){
stop('Specified "CODE" column not valid.')
}
if(!(Norm %in% list(T,F))){
stop('Specified "Norm" not a logical.')
}
for( iii in unique(mydata[,Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else{
mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]<- (max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]) - mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]+1)/max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]<-mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]/sum(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience])
}
}
}
return(mydata)
}
Book1<-CalculateSalience(Book1,Order="ORDER_NC", Subj="ID_NC",Norm=T)
Book1<-CalculateSalience(Book1,Order="ORDER_NC",CODE="CODSAFSDA" Subj="ID_NC",Norm=T)
Book1<-CalculateSalience(Book1,Order="ORDER_NC",CODE="CODSAFSDA" Subj="ID_NC",Norm=T)
Book1<-CalculateSalience(Book1,Order="ORDER_NC",CODE="CODSAFSDA",Subj="ID_NC",Norm=T)
Book1<-CalculateSalience(Book1,Order="ORDER_NC",CODE="CODE",Subj="ID_NC",Norm=T)
colnames(Book1)
which( (Book1[,Subj]==2) && !is.na(Book1[,CODE])
)
Subj="ID_NC"
CODE="CODE"
which( (Book1[,Subj]==2) && !is.na(Book1[,CODE]))
which( (Book1[,Subj]==1) && !is.na(Book1[,CODE]))
which( (Book1[,Subj]==3) && !is.na(Book1[,CODE]))
which( (Book1[,Subj]==3)
)
which( (Book1[,Subj]==3))
(Book1[,Subj]
)
(Book1[,Subj])==1
level(Book1[,Subj])
levels(Book1[,Subj])
levels(Book1[,Subj])[1]
levels(Book1[,Subj])[2]
levels(Book1[,Subj])[3]
levels(Book1[,Subj])[4]
unique(Book1[,Subj])
testnum= unique(Book1[,Subj])[3]
testnum
which( (mydata[,Subj]==testnum) && !is.na(mydata[,CODE])
)
which( (Book1[,Subj]==testnum) && !is.na(Book1[,CODE]))
which( (Book1[,Subj]==testnum)
)
which(!is.na(Book1[,CODE]))
which( (mydata[,Subj]==testnum) && !is.na(mydata[,CODE]))
which( (Book1[,Subj]==testnum) && !is.na(Book1[,CODE]))
testnum= unique(Book1[,Subj])[2]
which( (Book1[,Subj]==testnum) && !is.na(Book1[,CODE]))
testnum= unique(Book1[,Subj])[6]
which( (Book1[,Subj]==testnum) && !is.na(Book1[,CODE]))
which(!is.na(Book1[,CODE]))
which( (Book1[,Subj]==testnum))
which( (Book1[,Subj]==testnum) & !is.na(Book1[,CODE]))
CalculateSalience <-
function(mydata, Order="Order",Subj="Subj",CODE="CODE",Norm=FALSE,Salience="Salience"){
##This is a script which, given a dataset containing a list of subjects,
##and an ordering of responses will compute the "salience" of each response.
##Salience is effectively "What fraction of the way up the list are we?"
##If an individual gives five responses to a freelisting question,
##the first will have salience 1, the second 4/5, the third 3/5 and so on.
##  If the "Normalise" value is true, saliences will be normalised such that each individual has
## a total salience of 1. Otherwise, the set will be normalised so they have a maximum salience of 1.
if(!(class(mydata)=="data.frame" )){
stop('"mydata" is not a data frame. That will make things not work.')
}
mydata[,Salience]<- 0
badSubjects=list()
if(!(Order %in% colnames(mydata))){
stop('Specified "Order" column not valid.')
}
if(!(Subj %in% colnames(mydata))){
stop('Specified "Subj" column not valid.')
}
if(!(CODE %in% colnames(mydata))){
stop('Specified "CODE" column not valid.')
}
if(!(Norm %in% list(T,F))){
stop('Specified "Norm" not a logical.')
}
for( iii in unique(mydata[,Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else if{which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE]))}
else{
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<- (max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]) - mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]+1)/max(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<-mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]/sum(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience])
}
}
}
return(mydata)
}
CalculateSalience <-
function(mydata, Order="Order",Subj="Subj",CODE="CODE",Norm=FALSE,Salience="Salience"){
##This is a script which, given a dataset containing a list of subjects,
##and an ordering of responses will compute the "salience" of each response.
##Salience is effectively "What fraction of the way up the list are we?"
##If an individual gives five responses to a freelisting question,
##the first will have salience 1, the second 4/5, the third 3/5 and so on.
##  If the "Normalise" value is true, saliences will be normalised such that each individual has
## a total salience of 1. Otherwise, the set will be normalised so they have a maximum salience of 1.
if(!(class(mydata)=="data.frame" )){
stop('"mydata" is not a data frame. That will make things not work.')
}
mydata[,Salience]<- 0
badSubjects=list()
if(!(Order %in% colnames(mydata))){
stop('Specified "Order" column not valid.')
}
if(!(Subj %in% colnames(mydata))){
stop('Specified "Subj" column not valid.')
}
if(!(CODE %in% colnames(mydata))){
stop('Specified "CODE" column not valid.')
}
if(!(Norm %in% list(T,F))){
stop('Specified "Norm" not a logical.')
}
for( iii in unique(mydata[,Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else if{which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE]))}
else{
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<- (max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]) - mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]+1)/max(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<-mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]/sum(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience])
}
}
}
return(mydata)
}
CalculateSalience <-
function(mydata, Order="Order",Subj="Subj",CODE="CODE",Norm=FALSE,Salience="Salience"){
##This is a script which, given a dataset containing a list of subjects,
##and an ordering of responses will compute the "salience" of each response.
##Salience is effectively "What fraction of the way up the list are we?"
##If an individual gives five responses to a freelisting question,
##the first will have salience 1, the second 4/5, the third 3/5 and so on.
##  If the "Normalise" value is true, saliences will be normalised such that each individual has
## a total salience of 1. Otherwise, the set will be normalised so they have a maximum salience of 1.
if(!(class(mydata)=="data.frame" )){
stop('"mydata" is not a data frame. That will make things not work.')
}
mydata[,Salience]<- 0
badSubjects=list()
if(!(Order %in% colnames(mydata))){
stop('Specified "Order" column not valid.')
}
if(!(Subj %in% colnames(mydata))){
stop('Specified "Subj" column not valid.')
}
if(!(CODE %in% colnames(mydata))){
stop('Specified "CODE" column not valid.')
}
if(!(Norm %in% list(T,F))){
stop('Specified "Norm" not a logical.')
}
for( iii in unique(mydata[,Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else if{which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE]))
warning(paste('Subject',iii,'did not list anything. They will get no salience scores.') )
}else{
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<- (max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]) - mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]+1)/max(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<-mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]/sum(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience])
}
}
}
return(mydata)
}
which( (Book1[,Subj]==testnum) & !is.na(Book1[,CODE]))
length(which( (Book1[,Subj]==testnum) & !is.na(Book1[,CODE])))
CalculateSalience <-
function(mydata, Order="Order",Subj="Subj",CODE="CODE",Norm=FALSE,Salience="Salience"){
##This is a script which, given a dataset containing a list of subjects,
##and an ordering of responses will compute the "salience" of each response.
##Salience is effectively "What fraction of the way up the list are we?"
##If an individual gives five responses to a freelisting question,
##the first will have salience 1, the second 4/5, the third 3/5 and so on.
##  If the "Normalise" value is true, saliences will be normalised such that each individual has
## a total salience of 1. Otherwise, the set will be normalised so they have a maximum salience of 1.
if(!(class(mydata)=="data.frame" )){
stop('"mydata" is not a data frame. That will make things not work.')
}
mydata[,Salience]<- 0
badSubjects=list()
if(!(Order %in% colnames(mydata))){
stop('Specified "Order" column not valid.')
}
if(!(Subj %in% colnames(mydata))){
stop('Specified "Subj" column not valid.')
}
if(!(CODE %in% colnames(mydata))){
stop('Specified "CODE" column not valid.')
}
if(!(Norm %in% list(T,F))){
stop('Specified "Norm" not a logical.')
}
for( iii in unique(mydata[,Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else if( length(which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])))==0 ){
warning(paste('Subject',iii,'did not list anything. They will get no salience scores.') )
}else{
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<- (max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]) - mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]+1)/max(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<-mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]/sum(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience])
}
}
}
return(mydata)
}
CalculateSalience <-
function(mydata, Order="Order",Subj="Subj",CODE="CODE",Norm=FALSE,Salience="Salience"){
##This is a script which, given a dataset containing a list of subjects,
##and an ordering of responses will compute the "salience" of each response.
##Salience is effectively "What fraction of the way up the list are we?"
##If an individual gives five responses to a freelisting question,
##the first will have salience 1, the second 4/5, the third 3/5 and so on.
##  If the "Normalise" value is true, saliences will be normalised such that each individual has
## a total salience of 1. Otherwise, the set will be normalised so they have a maximum salience of 1.
if(!(class(mydata)=="data.frame" )){
stop('"mydata" is not a data frame. That will make things not work.')
}
mydata[,Salience]<- 0
badSubjects=list()
if(!(Order %in% colnames(mydata))){
stop('Specified "Order" column not valid.')
}
if(!(Subj %in% colnames(mydata))){
stop('Specified "Subj" column not valid.')
}
if(!(CODE %in% colnames(mydata))){
stop('Specified "CODE" column not valid.')
}
if(!(Norm %in% list(T,F))){
stop('Specified "Norm" not a logical.')
}
for( iii in unique(mydata[,Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else if( length(which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])))==0 ){
warning(paste('Subject',iii,'did not list anything. They will get no salience scores.') )
}else{
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<- (max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]) - mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]+1)/max(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<-mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Salience]/sum(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience])
}
}
}
return(mydata)
}
CalculateSalience(Book1,Order="ORDER_NC",Subj="ID_NC",CODE="CODE")
iii=testnum
mydata<-Book1
which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE]))
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]
Salience="Salience"
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]
(max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order])
)
ORDER="ORDER_NC"
(max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]))
Order="ORDER_NC"
(max(mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]))
mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]
mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), ]
mydata[which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE])), Order]
Subj
which( (mydata[,Subj]==iii) && !is.na(mydata[,CODE]))
CalculateSalience <-
function(mydata, Order="Order",Subj="Subj",CODE="CODE",Norm=FALSE,Salience="Salience"){
##This is a script which, given a dataset containing a list of subjects,
##and an ordering of responses will compute the "salience" of each response.
##Salience is effectively "What fraction of the way up the list are we?"
##If an individual gives five responses to a freelisting question,
##the first will have salience 1, the second 4/5, the third 3/5 and so on.
##  If the "Normalise" value is true, saliences will be normalised such that each individual has
## a total salience of 1. Otherwise, the set will be normalised so they have a maximum salience of 1.
if(!(class(mydata)=="data.frame" )){
stop('"mydata" is not a data frame. That will make things not work.')
}
mydata[,Salience]<- 0
badSubjects=list()
if(!(Order %in% colnames(mydata))){
stop('Specified "Order" column not valid.')
}
if(!(Subj %in% colnames(mydata))){
stop('Specified "Subj" column not valid.')
}
if(!(CODE %in% colnames(mydata))){
stop('Specified "CODE" column not valid.')
}
if(!(Norm %in% list(T,F))){
stop('Specified "Norm" not a logical.')
}
for( iii in unique(mydata[,Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else if( length(which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])))==0 ){
warning(paste('Subject',iii,'did not list anything. They will get no salience scores.') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else{
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<- (max(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]) - mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]+1)/max(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<-mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]/sum(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience])
}
}
}
return(mydata)
}
CalculateSalience(Book1,Order="ORDER_NC",Subj="ID_NC",CODE="CODE")
Book1<-CalculateSalience(Book1,Order="ORDER_NC",Subj="ID_NC",CODE="CODE")
View(Book1)
Book1<-CalculateSalience(Book1,Order="ORDER_NC",Subj="ID_NC",CODE="BAD_SPEC_TL")
View(Book1)
View(FruitList)
unique(FruitList[,Subj])
unique(FruitList[,"Subj"])
unique(FruitList[,["Subj","CODE"] ])
unique(FruitList[,c("Subj","CODE") ])
unique(FruitList[,c("Subj","CODE") ])[3]
unique(FruitList[,c("Subj","CODE") ])
str(unique(FruitList[,c("Subj","CODE") ]))
for(iii in unique(FruitList[,c("Subj","CODE") ]){print("iii") }
for(iii in unique(FruitList[,c("Subj","CODE") ]){print(iii) }
for(iii in unique(FruitList[,c("Subj","CODE") ])){print(iii) }
for(iii in unique(FruitList[,c("Subj","CODE") ])){print("bob") }
for(iii in unique(FruitList[,c("Subj","CODE") ])){print("bob") }
CalculateSalience <-
function(mydata, Order="Order",Subj="Subj",CODE="CODE",GROUPING=NA,Norm=FALSE,Salience="Salience"){
##This is a script which, given a dataset containing a list of subjects,
##and an ordering of responses will compute the "salience" of each response.
##Salience is effectively "What fraction of the way up the list are we?"
##If an individual gives five responses to a freelisting question,
##the first will have salience 1, the second 4/5, the third 3/5 and so on.
##  If the "Normalise" value is true, saliences will be normalised such that each individual has
## a total salience of 1. Otherwise, the set will be normalised so they have a maximum salience of 1.
if(!(class(mydata)=="data.frame" )){
stop('"mydata" is not a data frame. That will make things not work.')
}
mydata[,Salience]<- 0
badSubjects=list()
if(!(Order %in% colnames(mydata))){
stop('Specified "Order" column not valid.')
}
if(!(Subj %in% colnames(mydata))){
stop('Specified "Subj" column not valid.')
}
if(!(CODE %in% colnames(mydata))){
stop('Specified "CODE" column not valid.')
}
if(!(Norm %in% list(T,F))){
stop('Specified "Norm" not a logical.')
}
if(!(GROUPING %in% colnames(mydata)) && !is.na(GROUPING)){
warning("Grouping column not found. Continuing without grouping.")
GROUPING=NA
}
if (is.na(GROUPING)){
for( iii in unique(mydata[,Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else if( length(which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])))==0 ){
warning(paste('Subject',iii,'did not list anything. They will get no salience scores.') )
mydata[which(mydata[,Subj]==iii), Salience]<-NA
}else{
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<- (max(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]) - mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]+1)/max(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<-mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]/sum(mydata[which( (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience])
}
}
}##End for loop
##End "No grouping" version.
}else{
for(ggg in unique(mydata[,GROUPING] ) ){
for( iii in unique(mydata[which(mydata[,GROUPING]==ggg),Subj])){
## for now I will assume that data is good and clean (no missing elements) and ordered.
## Will probably want to come back and deal with borked cases as needed later.
OrderList<-mydata[which(mydata[,GROUPING]==ggg & mydata[,Subj]==iii), Order]
if(!all(sort(OrderList)==seq(length(OrderList))) ){
warning(paste('Subject',iii,'has bad order data and can not have salience calculated') )
mydata[which(mydata[,GROUPING]==ggg & mydata[,Subj]==iii), Salience]<-NA
}else if( length(which(mydata[,GROUPING]==ggg & (mydata[,Subj]==iii) & !is.na(mydata[,CODE])))==0 ){
warning(paste('Subject',iii,'did not list anything. They will get no salience scores.') )
mydata[which(mydata[,GROUPING]==ggg & mydata[,Subj]==iii), Salience]<-NA
}else{
mydata[which(mydata[,GROUPING]==ggg & mydata[,Subj]==iii & !is.na(mydata[,CODE])), Salience]<- (max(mydata[which(mydata[,GROUPING]==ggg &  (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]) - mydata[which(mydata[,GROUPING]==ggg &  (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order]+1)/max(mydata[which(mydata[,GROUPING]==ggg &  (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Order])
if(Norm){
mydata[which(mydata[,GROUPING]==ggg &  (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]<-mydata[which(mydata[,GROUPING]==ggg &  (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience]/sum(mydata[which(mydata[,GROUPING]==ggg &  (mydata[,Subj]==iii) & !is.na(mydata[,CODE])), Salience])
}
}
}##End subj for loop
}##End GROUP for loop.
}
return(mydata)
}
Book1<-CalculateSalience(Book1,Order="ORDER_NC",Subj="ID_NC",CODE="BAD_SPEC_TL")
library("devtools")
library(roxygen2)
pwd()
wd()
setwd("C:\Users\Babblefish\Documents\Rprojects\Consensus\AnthroTools")
setwd("C:/Users/Babblefish/Documents/Rprojects/Consensus/AnthroTools")
wd()
setwd("C:/Users/Babblefish/Documents/Rprojects")
wd()
setwd("C:/Users/Babblefish/Documents/Rprojects/Consensus")
wd()
setwd("C:/Users/Babblefish/Documents/RProjects/Consensus")
wd()
setwd("C:/Users/Babblefish/Documents/RProjects/Consensus\")
kl
)
""
"
setwd("C:/Users/Babblefish/Documents/RProjects/Consensus")
wd()
setwd("~/RProjects/Consensus/AnthroTools")
wd()
document()
document()
document()
setwd("..")
install("AnthroTools")
help(AnthroTools)
setwd("~/RProjects/Consensus/AnthroTools")
document()
document()
